image_size: 256
experiment_name: unconditional

optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0001
  weight_decay: 0


vae:
  _target_: diffusers.models.AutoencoderKL.from_pretrained
  pretrained_model_name_or_path: "transformers/sd-vae-ft-ema/"


data:
  dataset:
    _target_: speed.dataset.image.image_dataset
    image_size: ${image_size}
    class_cond: false

  batch_size: 4 # 32
  num_workers: 4

model:
  _target_: speed.networks.dit.DiT_XL_2
  condition: none


sample:
  diffusion:
    timestep_respacing: '250'

inference:
  diffusion:
    timestep_respacing: '250'
  per_proc_batch_size: 32
  num_samples: 10000

epoch: 200_000
max_training_steps: 200_000

log_every: 100
ckpt_every: 10_000
